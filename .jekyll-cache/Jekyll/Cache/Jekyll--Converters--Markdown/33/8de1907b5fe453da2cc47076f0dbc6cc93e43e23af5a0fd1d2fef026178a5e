I"a;<blockquote>
  <p>Graph Representation Learning是GraphSAGE第一作者William Hamilton的新书，下载地址https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book.pdf</p>
</blockquote>

<h1 id="introduction">Introduction</h1>

<blockquote>
  <p>本章首先介绍了图这种数据结构，然后介绍了基于图的机器学习。</p>
</blockquote>

<p>图是一种无处不在的数据结构，是一种描述复杂系统的通用语言。一般来说，图只是对象（如节点）的集合，以及这些对象之间的交互（如边）。例如，要讲社交网络编码为图，我们可以使用节点来表示个人，使用边来表示两人是朋友（如图1.1所示）。</p>

<p><img style="display: block; margin: 0 auto" src="/img/post_images/Graph-Representation-Learning/1_1graph.png" alt="" /></p>

<div class="caption">图1.1 著名的Zachary空手道俱乐部网络代表了空手道俱乐部成员之间的友谊关系，这是Wayne W. Zachary在1970年至1972年研究的结果。如果两个人在俱乐部外有交流，则用边将它们连接起来。在Zachary的研究中，俱乐部分为两个部分——以节点0和33为中心——并且能够根据图结构正确预测节点属于哪个部分。</div>

<p>图形式的关键不仅在于它关注点之间的关系（并不是单个点属性），还在于它的普遍性。举几个例子，可以使用同一图形式来表示社交网络、药物和蛋白质之间的相互作用、分子中原子之间的相互作用或电信网络中终端之间的连接。</p>

<p>然而，图不仅仅提供了一个优雅的理论框架，还为我们提供了数学基础，我们可以以此为基础来分析、理解和学习现实世界中的复杂系统。在过去的二十五年中，研究人员可以使用的图结构化数据的数量和质量急剧增加。随着大规模社交网络平台的出现，出现了很多有意义的图数据供研究人员分析，挖掘这些数据的潜力是目前面临的挑战。</p>

<p>本书讲述了如何使用机器学习来应对这一挑战。当然，机器学习不是分析图结构数据的唯一方法（独立于机器学习的网络分析在这里将不进行详细介绍）。但是，鉴于要分析的图数据集的规模和复杂性不断增加，很明显，机器学习将在提高我们建模、分析和理解图数据的能力方面发挥重要作用。</p>

<h2 id="what-is-a-graph">What is a graph?</h2>

<p>在讨论图上的机器学习之前，有必要对”图数据“的确切含义进行更正式的描述。形式上，图$\mathcal{G}=(\mathcal{V}, \mathcal{E})$由一组节点$\mathcal{V}$和这些节点之间的一组边$\mathcal{E}$定义。我们将从节点$u \in \mathcal{V}$到节点$v \in \mathcal{V}$的边表示为$(u, v) \in \mathcal{E}$。在许多情况下，我们只关注简单图，其中每对节点之间最多有一条边，而没有节点与自身之间的边，并且这些边都是无向的，即$(u, v) \in \mathcal{E} \leftrightarrow (v, u) \in \mathcal{E}$。</p>

<p>表示图的一种简便方法是通过邻接矩阵$\mathbf{A} \in \mathbb{R}^{\vert \mathcal{V}\vert \times \vert\mathcal{V}\vert}$。为了用邻接矩阵表示图，我们对图中的节点进行排序，以使每个节点在邻接矩阵中索引特定的行和列。然后，我们可以将边表示为矩阵中的值：如果$(u, v) \in \mathcal{E}$，则$\mathbf{A}[u, v]=1$，否则$\mathbf{A}[u, v]=0$。如果图仅包含无向边，则$\mathbf{A}$是对称矩阵；如果图是有向的（即边方向很重要），则$\mathbf{A}$不一定是对称的。某些图也可以具有加权边，即邻接矩阵中的值是任意实数值，而不是$\{0, 1\}$。例如，蛋白质相互作用图中的加权边可能表示两种蛋白质之间关系的强度。</p>

<h3 id="multi-relational-graphs">Multi-relational Graphs</h3>

<p>除了无向、有向和加权边之间的区别，我们还考虑具有不同边类型的图。例如，在表示药物相互作用的图中，我们可能希望不同的边对应于同时服用药物时可能发生的不同的副作用。在这些情况下，我们可以扩展边符号以包括边和关系类型$\tau$，即$(u, \tau, v) \in \mathcal{E}$，并且可以为每个边类型定义一个邻接矩阵$\mathbf{A}_{\tau}$。我们称这类图为多关系图，整个图可以用邻接张量$\mathcal{A} \in \mathbb{R}^{\vert\mathcal{V}\vert \times \vert\mathcal{R}\vert \times \vert\mathcal{V}\vert}$来表示，其中$\mathcal{R}$是关系集。多关系图的两个重要子集是异构（heterogeneous）图和多重（multiplex）图。</p>

<p><strong>异构图</strong> 在异构图中，节点也有类型，这意味着我们可以将节点集划分为不相交的集合$\mathcal{V}=\mathcal{V}_1 \cup \mathcal{V}_2 \cup \cdots \mathcal{V}_k$，其中$\mathcal{V}_i \cap \mathcal{V} = \emptyset, \forall i \neq j$。异构图中的边通常根据节点类型满足约束条件，最常见的约束条件是某些边仅连接某些类型的节点，即$u, \tau_i, v) \in \mathcal{E} \rightarrow u \in \mathcal{V}_j, v \in \mathcal{V}_k$。例如，在异质生物医学图中，可能存在代表蛋白质的节点，代表药物的节点和代表疾病的节点。代表“治疗”的边只会出现在药物节点和疾病节点之间。类似地，代表“多药副作用”的边只会出现在两个药物节点之间。多部（Multipartite）图是异构图的一种特殊情况，其中边只能连接具有不同类型的节点，即$(u, \tau_i, v) \in \mathcal{E} \rightarrow u \in \mathcal{V}_j, v \in \mathcal{V}_k \wedge j \neq k$。</p>

<p><strong>多重图</strong> 在多重图中，我们假设该图可以分解为$k$层。假设每层都包括所有节点，且每层对应唯一一个关系，表示该层的层内边类型。我们还假设存在层间边类型，这些类型跨层连接同一节点。通过示例可以更好地理解多重图。例如，在多重运输网络中，每个节点可能代表一座城市，而每一层可能代表不同的运输方式（例如，空中运输或火车运输）。层内边将代表通过不同交通方式连接的城市，而层间边则代表在某一城市内可以转换交通方式的可能性。</p>

<blockquote>
  <p>简单来说，多重图就是该图允许某两节点之间边数多于一条，且允许顶点自连接。</p>
</blockquote>

<h3 id="feature-information">Feature Information</h3>

<p>最后，在多数情况下，还有与图关联的属性或特征信息（例如，与社交网络中的用户关联的个人资料图片）。通常，这些是节点级的属性，我们用实值矩阵$\mathbf{X} \in \mathbb{R}^{\vert \mathcal{V} \vert \times m}$表示，其中假定节点的顺序与邻接矩阵中的顺序一致。在异构图中，我们通常假定每种不同类型的节点都有其独特的属性类型。在极少数情况下，我们还将考虑除离散边类型外还具有实值边特征的图，在某些情况下，我们甚至将实值特征与整个图相关联。</p>

<h2 id="machine-learning-on-graphs">Machine learning on graphs</h2>

<p>机器学习本质上是一个问题驱动的学科。我们寻求构建可以从数据中学习的模型以解决特定任务，并且机器学习模型通常根据其寻求解决的任务类型进行分类：是监督任务（目的是通过给定输入数据预测输出结果）还是无监督任务（目的是推断数据的模式，例如点簇）。</p>

<p>使用图进行机器学习没有什么不同，但是对于图来说，有监督和无监督的通用类别不一定是最有用的信息。在本节中，我们简要概述了图数据上最重要且经过充分研究的机器学习任务。就像我们将看到的那样，“监督”问题再图数据中很普遍，但是图上的机器学习问题通常会模糊传统机器学习类别之间的界限。</p>

<h3 id="node-classification">Node classification</h3>

<p>假设我们拥有一个拥有数百万用户的大型社交网络数据集，但是这些用户中的很大一部分实际上的机器人。出于多种原因，识别这些机器人可能很重要：公司可能不希望向机器人做广告，或者机器人实际上可能违反了社交网络的服务条款。手动检查每个用户以确定他们是否是机器人会非常昂贵，因此理想情况下，我们希望有一个模型可以只通过少量手动标记的示例就将能用户分类为机器人（或不分类为机器人）。</p>

<p>这是节点分类的经典示例，当我们仅在训练中获得真实的标签时，目的是预测与所有节点$u \in \mathcal{V}$相关联的标签$y_u$（可以使类型、类别或属性）。节点分类可能是图数据上最流行的机器学习任务，尤其是近些年来。社交网络以外的节点分类示例包括对交互组中蛋白质的功能进行分类，并基于超链接或引文图对文档主题进行分类。通常，我们假设仅对单个图中的一小部分节点标注标签（例如，从一小组手动标记的示例中对社交网络中的机器人进行分类）。但是，也存在节点分类的情况，涉及许多标记的节点和/或需要在不连续的图上进行概括（例如，对不同物种的相互作用基因组中蛋白质的功能进行分类）。</p>

<p>乍一看，节点分类似乎是标准有监督分类的直接变体，但实际上存在着很大区别。最重要的区别是图中的节点不是独立的，也不是均匀分布的。通常，当我们建立有监督机器学习模型时，我们假设每个数据点在统计上都独立于其他所有数据点。否则，我们可能需要对所有输入点之间的依赖关系进行建模。我们还假设数据点是均匀分布的；否则，我们无法保证模型可以推广到新的数据点。节点分类彻底打破了这个独立且均匀分布的假设。我们改为建模一组互连的节点，而不是建模一组独立且均匀分布的数据点。</p>

<p>实际上，许多最成功的的节点分类方法背后的关键在于显示地利用节点之间的连接。一种特别流行的想法是利用同质性，即节点趋向于与图中的邻居共享属性的趋势。例如，人们倾向于与拥有相同兴趣或人口统计特征的其他人形成友谊。基于同构的概念，我们可以建立机器学习模型，尝试为图中的相邻接点分配相似的标签。除了同构以外，还存在诸如结构等价的概念，即具有相似局部邻域结构的节点将具有相似标签的概念以及异同，这意味着节点将优先连接到带有不同标签的节点（例如，性别是在许多社交网络中都表现出异质性的属性）。当我们建立节点分类模型时，我们想利用这些概念并对节点之间的关系进行建模，而不是简单地将节点视为独立的数据点。</p>

<blockquote>
  <p><strong>有监督还是半监督？</strong> 由于节点分类的非典型性，研究人员经常将其称为半监督（semi-supervised）。之所以使用此术语，是因为当我们训练节点分类模型时，我们通常可以访问完整的图，包括所有未标记的（例如测试）节点。我们唯一缺少的是测试节点的标签。但是，我们仍然可以使用有关测试节点的信息（例如，图中邻居节点的信息）来在训练中改善模型。这与通常的有监督设置不同，后者在训练过程中完全看不到未标记的数据点。</p>

  <p>训练中将带标签的数据和不带标签的数据合并的模型的通用术语是半监督学习，因此可以理解，该术语经常用于节点分类任务。不过，必须注意的是，半监督学习的标准公式仍然需要独立且均匀分布假设，这并不适用于节点分类。图上的机器学习任务很难满足我们的标准分类！</p>
</blockquote>

<h3 id="relation-prediction">Relation prediction</h3>

<p>节点分类对于基于节点与图中其他节点的关系来推断有关节点的信息很有用。但是，如果我们缺少此关系信息，情况又如何呢？如果我们只知道给定细胞中存在的一些蛋白质相互作用，但我们想对缺少的相互作用做出一个很好的猜测，该怎么办？我们可以使用机器学习来推断图中节点之间的边吗？</p>

<p>根据特定的应用领域，此任务有很多名称，例如链路预测、图谱补全和关系推断。在这里，我们将其简称为关系预测。与节点分类一起，它是具有图数据的较流行的机器学习任务之一，并且具有无数的实际应用：向社交平台中的用户推荐内容，预测药物副作用，或在关系数据库中推断新事实，所有这些任务都可以视为关系预测的特殊情况。</p>

<p>关系预测的标准设置是给我们提供一组节点$\mathcal{V}$和这些节点之间不完整的边集$\mathcal{E}<em>{train} \subset \mathcal{E}$。 我们的目标是使用这一部分信息来推断缺失的边$\mathcal{E} \ \mathcal{E}</em>{train}$。此任务的复杂度高度取决于我们使用的图数据的类型。例如，在简单图中（例如仅对“友谊”关系进行编码的社交网络），存在基于两个几点共享多少邻居并可以实现出色性能的简单启发式方法。另一方面，在更复杂的多关系图数据集中，例如编码数百种不同生物相互作用的生物医学知识图，关系预测可能需要复杂的推理和推理策略。像节点分类一样，关系预测模糊了传统机器学习类别的边界（通常被称为有监督和无监督的），并且它需要特定于图域的归纳偏差。此外，像节点分类一样，关系预测也有很多变体，包括在单个固定图上进行预测的设置，以及必须在多个不相交图上预测关系的设置。</p>

<h3 id="clustering-and-community-detection">Clustering and community detection</h3>

<p>节点分类和关系预测都需要推断关于图数据的丢失信息，并且在许多方面，这两个任务是监督学习的图类比。另一方面，社区检测是无监督聚类的图类比。</p>

<p>假设我们可以访问Google学术搜索中的所有引文信息，并且我们制作了一个协作图，将两位研究人员共同撰写论文的情况联系起来。如果我们要研究这个网络，我们是否会期望找到一个密集的“毛线球”，让每个人都同样有可能与其他人合作？该图更有可能分离为不同的节点簇，并按研究领域、机构或其他人口统计学因素进行分组。换句话说，我们希望该网络（像许多现实网络一样）表现出社区结构，其中节点更有可能与属于同一社区的节点形成边。</p>

<p>这是社区检测任务的基本直觉。社区检测的挑战是仅在输入图$\mathcal{G} = (\mathcal{V}, \mathcal{E})$的情况下推断潜在的社区结构。社区检测在现实世界中的许多应用包括发现遗传交互网络中的功能模块和发现金融交易网络中的欺诈性用户组。</p>
:ET